{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !uv pip install -r ../requirements.txt # if using uv\n",
    "!pip install -r ../requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill all connections to the database before running this notebook\n",
    "\n",
    "import psycopg\n",
    "import os \n",
    "\n",
    "with psycopg.connect(dbname='postgres', user=os.getenv('POSTGRES_USER'), password=os.getenv('POSTGRES_PASSWORD'), host='localhost') as conn:\n",
    "    conn.autocommit = True\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT pg_terminate_backend(pid)\n",
    "            FROM pg_stat_activity\n",
    "            WHERE datname = 'test_db'\n",
    "              AND pid <> pg_backend_pid();\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..') # to be able to import \n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from db_utils import (create_db, create_embeddings_table,\n",
    "                      create_pgvector_extension, delete_db,\n",
    "                      insert_data_into_table, pg_connection)\n",
    "from embed import HFModels\n",
    "from retrieval import semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_encodings(\n",
    "        sentences: list, \n",
    "        model: SentenceTransformer = HFModels.default.value,\n",
    "        save_to_file: bool = True, \n",
    "        filename: str = 'data/example_embeddings.npy'\n",
    "        ) -> np.ndarray:\n",
    "    \n",
    "    try:\n",
    "        embeddings = np.load(filename)\n",
    "        print(f\"Loaded embeddings from '{filename}'\")\n",
    "        return embeddings\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found. Generating embeddings...\")\n",
    "\n",
    "    model: SentenceTransformer = SentenceTransformer(HFModels.default.value)\n",
    "    embeddings: np.ndarray = model.encode(sentences=sentences) # shape: (len(sentences), 384)\n",
    "    if save_to_file: np.save('example_embeddings.npy', embeddings)\n",
    "        \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Database test_db deleted\n",
      "INFO:root:Database 'test_db' created successfully\n",
      "INFO:root:pgvector extension created\n",
      "INFO:root:Embeddings table 'pg_embeddings_test' created.\n",
      "/tmp/ipykernel_68893/2100576212.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql_query(f'SELECT * FROM {tb_name}', CONN)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, chunk, embedding]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the database and embeddings table\n",
    "db_name = 'test_db'\n",
    "delete_db(db_name) # delete if exists\n",
    "create_db(db_name=db_name)\n",
    "create_pgvector_extension(db_name)\n",
    "create_embeddings_table(db_name)\n",
    "CONN = pg_connection(db_name)\n",
    "tb_name = 'pg_embeddings_test'\n",
    "pd.read_sql_query(f'SELECT * FROM {tb_name}', CONN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data inserted into table 'pg_embeddings_test'. Failed chunks: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings from 'data/example_embeddings.npy'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68893/3149469815.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql_query(f'SELECT * FROM {tb_name}', CONN)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07b101d8-108c-47e3-92fa-98b2a3a4d6a7</td>\n",
       "      <td>I'm a physicist and a Data Scientist</td>\n",
       "      <td>[-0.048952606,-0.057101876,0.028381784,0.09913...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15b34629-043c-4a46-805e-bf85d12a179a</td>\n",
       "      <td>I don't linke the Copenhagen interpretation</td>\n",
       "      <td>[-0.0031696414,0.07755055,0.009189781,0.029925...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  07b101d8-108c-47e3-92fa-98b2a3a4d6a7   \n",
       "1  15b34629-043c-4a46-805e-bf85d12a179a   \n",
       "\n",
       "                                         chunk  \\\n",
       "0         I'm a physicist and a Data Scientist   \n",
       "1  I don't linke the Copenhagen interpretation   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.048952606,-0.057101876,0.028381784,0.09913...  \n",
       "1  [-0.0031696414,0.07755055,0.009189781,0.029925...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"I'm a physicist and a Data Scientist\", \"I don't linke the Copenhagen interpretation\"]\n",
    "embeddings: np.ndarray = generate_encodings(sentences)\n",
    "embeddings = embeddings.tolist()\n",
    "insert_data_into_table(db_name, sentences, embeddings, tb_name)\n",
    "pd.read_sql_query(f'SELECT * FROM {tb_name}', CONN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146e55db0ce44b8e85e1154828527748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of retrieval\n",
    "\n",
    "query = 'copenhagen'\n",
    "res = semantic(query, 'test_db', tb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 1: (\"I don't linke the Copenhagen interpretation\", 0.35559275084625686)\n",
      "result 2: (\"I'm a physicist and a Data Scientist\", 0.8650325387716256)\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(res, start=1):\n",
    "    print(f\"result {i}: {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONN.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comment out if you want to delete the database\n",
    "# delete_db(db_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
